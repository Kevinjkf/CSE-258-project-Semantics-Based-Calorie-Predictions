{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    return words\n",
    "\n",
    "def build_vocabulary(corpus):\n",
    "    vectorizer = CountVectorizer(tokenizer=preprocess_text, stop_words='english')\n",
    "    vectorizer.fit(tqdm(corpus, desc='Building vocabulary'))\n",
    "    return vectorizer\n",
    "\n",
    "def compute_bow(corpus, vectorizer):\n",
    "    return vectorizer.transform(tqdm(corpus, desc='Computing BoW'))\n",
    "\n",
    "def compute_tfidf(corpus, word2ind):\n",
    "    vectorizer = TfidfVectorizer(vocabulary=word2ind, tokenizer=preprocess_text, stop_words='english')\n",
    "    return vectorizer.fit_transform(tqdm(corpus, desc='Computing TF-IDF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import json\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "train_file = '../../dataset/processed/train_data.csv'\n",
    "data = pd.read_csv(train_file)\n",
    "\n",
    "word_freq = Counter()\n",
    "\n",
    "\n",
    "for steps in data['steps']:\n",
    "    steps_list = eval(steps)    \n",
    "    for step in steps_list:\n",
    "        step_clean = re.sub(r'[^\\w\\s]', '', step).lower()\n",
    "        words = step_clean.split()\n",
    "        words_filtered = [word for word in words if word not in stop_words]\n",
    "\n",
    "        word_freq.update(words_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ball',\n",
       " 'base',\n",
       " 'cold',\n",
       " 'ham',\n",
       " 'small',\n",
       " 'would',\n",
       " 'seasoning',\n",
       " 'rings',\n",
       " 'along',\n",
       " 'right',\n",
       " 'refrigerated',\n",
       " 'blender',\n",
       " 'preheated',\n",
       " 'mash',\n",
       " 'core',\n",
       " 'except',\n",
       " 'shredded',\n",
       " 'chives',\n",
       " 'pizza',\n",
       " 'vinegar',\n",
       " 'well',\n",
       " 'vanilla',\n",
       " 'loaf',\n",
       " 'try',\n",
       " 'big',\n",
       " 'brown',\n",
       " 'cook',\n",
       " 'pink',\n",
       " 'minced',\n",
       " 'end',\n",
       " 'stuff',\n",
       " 'twice',\n",
       " 'chunks',\n",
       " 'raisins',\n",
       " 'even',\n",
       " 'broil',\n",
       " 'crab',\n",
       " 'gradually',\n",
       " 'ketchup',\n",
       " 'bars',\n",
       " 'skim',\n",
       " 'stand',\n",
       " 'larger',\n",
       " 'custard',\n",
       " 'broiler',\n",
       " 'necessary',\n",
       " 'tea',\n",
       " 'beaten',\n",
       " 'walnuts',\n",
       " 'rack',\n",
       " 'carrots',\n",
       " 'place',\n",
       " 'crush',\n",
       " 'balsamic',\n",
       " 'texture',\n",
       " 'blended',\n",
       " 'tender',\n",
       " 'swirl',\n",
       " 'check',\n",
       " 'slowly',\n",
       " 'seconds',\n",
       " 'freshly',\n",
       " 'microwave',\n",
       " 'thin',\n",
       " 'crock',\n",
       " 'bubbling',\n",
       " 'dry',\n",
       " 'wash',\n",
       " 'roll',\n",
       " 'give',\n",
       " 'prepared',\n",
       " 'trim',\n",
       " 'next',\n",
       " 'cool',\n",
       " 'tops',\n",
       " 'chops',\n",
       " 'shells',\n",
       " 'half',\n",
       " 'container',\n",
       " 'dissolves',\n",
       " 'hour',\n",
       " 'tin',\n",
       " 'toasted',\n",
       " 'skillet',\n",
       " 'completely',\n",
       " 'thermometer',\n",
       " 'beans',\n",
       " 'continue',\n",
       " 'steam',\n",
       " 'bananas',\n",
       " 'coarsely',\n",
       " 'aluminum',\n",
       " 'allow',\n",
       " 'lengthwise',\n",
       " 'pumpkin',\n",
       " 'thickness',\n",
       " 'keep',\n",
       " 'become',\n",
       " 'often',\n",
       " 'soften',\n",
       " 'incorporated',\n",
       " 'nice',\n",
       " 'teaspoon',\n",
       " 'mixing',\n",
       " 'process',\n",
       " 'salted',\n",
       " 'cherries',\n",
       " 'condensed',\n",
       " 'sticks',\n",
       " 'chilled',\n",
       " 'times',\n",
       " 'needed',\n",
       " 'fold',\n",
       " 'running',\n",
       " 'squares',\n",
       " 'hamburger',\n",
       " 'flakes',\n",
       " 'meat',\n",
       " 'buttered',\n",
       " 'chop',\n",
       " 'almond',\n",
       " 'muffin',\n",
       " 'second',\n",
       " 'sage',\n",
       " 'fit',\n",
       " '25',\n",
       " 'vinaigrette',\n",
       " 'marinate',\n",
       " 'pastry',\n",
       " 'stick',\n",
       " 'sherry',\n",
       " 'flour',\n",
       " 'cup',\n",
       " 'form',\n",
       " 'glass',\n",
       " '45',\n",
       " 'foil',\n",
       " 'bread',\n",
       " 'package',\n",
       " 'towels',\n",
       " 'platter',\n",
       " 'degrees',\n",
       " 'roasting',\n",
       " 'partially',\n",
       " 'lid',\n",
       " 'desired',\n",
       " 'peanut',\n",
       " 'macaroni',\n",
       " 'apple',\n",
       " 'ladle',\n",
       " 'easily',\n",
       " 'using',\n",
       " 'shake',\n",
       " 'fridge',\n",
       " 'teaspoons',\n",
       " 'burn',\n",
       " 'worcestershire',\n",
       " 'together',\n",
       " 'skewers',\n",
       " 'margarine',\n",
       " 'leaf',\n",
       " 'freezer',\n",
       " 'thyme',\n",
       " 'uncovered',\n",
       " 'green',\n",
       " 'dollop',\n",
       " 'arrange',\n",
       " 'slice',\n",
       " 'balls',\n",
       " 'paper',\n",
       " 'c',\n",
       " 'honey',\n",
       " 'pinch',\n",
       " '375f',\n",
       " 'reserved',\n",
       " 'wedges',\n",
       " 'fish',\n",
       " 'flame',\n",
       " 'great',\n",
       " 'little',\n",
       " 'seasoned',\n",
       " 'sift',\n",
       " 'grill',\n",
       " 'delicious',\n",
       " 'pine',\n",
       " 'grease',\n",
       " 'portion',\n",
       " 'scoop',\n",
       " 'x',\n",
       " 'separate',\n",
       " 'sprayed',\n",
       " 'browning',\n",
       " 'away',\n",
       " 'pepper',\n",
       " 'divide',\n",
       " 'coated',\n",
       " 'almost',\n",
       " 'flatten',\n",
       " 'wings',\n",
       " 'overnight',\n",
       " 'way',\n",
       " 'marinade',\n",
       " 'bags',\n",
       " 'cheese',\n",
       " 'frying',\n",
       " '12',\n",
       " '2inch',\n",
       " 'pan',\n",
       " 'days',\n",
       " 'combine',\n",
       " 'begin',\n",
       " 'cooker',\n",
       " 'bottom',\n",
       " '11',\n",
       " 'candy',\n",
       " 'reserving',\n",
       " 'servings',\n",
       " 'layers',\n",
       " 'puree',\n",
       " 'speed',\n",
       " 'edges',\n",
       " 'remaining',\n",
       " 'waxed',\n",
       " '8inch',\n",
       " 'much',\n",
       " 'ribs',\n",
       " 'grate',\n",
       " 'rum',\n",
       " 'strawberries',\n",
       " 'get',\n",
       " 'may',\n",
       " 'beat',\n",
       " 'turn',\n",
       " '35',\n",
       " 'quickly',\n",
       " 'slotted',\n",
       " 'halfway',\n",
       " 'bubbles',\n",
       " 'yolks',\n",
       " 'constantly',\n",
       " '34',\n",
       " 'taste',\n",
       " '6',\n",
       " 'lower',\n",
       " 'creamed',\n",
       " 'til',\n",
       " 'chicken',\n",
       " 'shape',\n",
       " 'used',\n",
       " 'individual',\n",
       " 'prepare',\n",
       " 'drained',\n",
       " 'measuring',\n",
       " 'combined',\n",
       " 'shred',\n",
       " 'cottage',\n",
       " 'also',\n",
       " 'water',\n",
       " 'back',\n",
       " 'setting',\n",
       " 'moistened',\n",
       " 'syrup',\n",
       " 'thinly',\n",
       " 'thaw',\n",
       " 'peas',\n",
       " 'stove',\n",
       " 'dark',\n",
       " 'bean',\n",
       " 'seasonings',\n",
       " 'cracker',\n",
       " 'leeks',\n",
       " 'maple',\n",
       " 'herbs',\n",
       " 'spinach',\n",
       " 'cubes',\n",
       " 'broccoli',\n",
       " 'spray',\n",
       " 'onions',\n",
       " 'fat',\n",
       " 'apples',\n",
       " 'squash',\n",
       " 'served',\n",
       " 'brush',\n",
       " 'mixer',\n",
       " 'inserted',\n",
       " 'cumin',\n",
       " 'french',\n",
       " 'marshmallows',\n",
       " 'occasionally',\n",
       " 'firm',\n",
       " 'griddle',\n",
       " 'food',\n",
       " 'ginger',\n",
       " 'cream',\n",
       " 'spread',\n",
       " 'strainer',\n",
       " 'lined',\n",
       " 'freeze',\n",
       " 'glaze',\n",
       " 'dish',\n",
       " '350f',\n",
       " 'best',\n",
       " 'knife',\n",
       " 'crosswise',\n",
       " 'plate',\n",
       " 'orange',\n",
       " 'flavor',\n",
       " 'return',\n",
       " 'nonstick',\n",
       " 'rectangle',\n",
       " 'tray',\n",
       " 'usually',\n",
       " 'olive',\n",
       " 'milk',\n",
       " '30',\n",
       " 'rest',\n",
       " 'pans',\n",
       " 'stems',\n",
       " 'making',\n",
       " 'patties',\n",
       " 'topped',\n",
       " 'finely',\n",
       " '18',\n",
       " 'whip',\n",
       " 'gelatin',\n",
       " 'chips',\n",
       " 'toss',\n",
       " 'tbsp',\n",
       " 'scraping',\n",
       " 'meal',\n",
       " 'beer',\n",
       " 'covered',\n",
       " 'sheet',\n",
       " 'finger',\n",
       " 'cake',\n",
       " 'spaghetti',\n",
       " 'crumbly',\n",
       " 'eggs',\n",
       " 'adding',\n",
       " 'saucepan',\n",
       " 'drizzle',\n",
       " 'cranberries',\n",
       " 'jelly',\n",
       " 'center',\n",
       " 'addition',\n",
       " 'refrigerate',\n",
       " 'assemble',\n",
       " 'squeeze',\n",
       " 'cooked',\n",
       " 'sticking',\n",
       " 'fragrant',\n",
       " 'fried',\n",
       " 'look',\n",
       " 'mediumlow',\n",
       " 'jars',\n",
       " 'creamy',\n",
       " 'melted',\n",
       " 'middle',\n",
       " 'ahead',\n",
       " 'least',\n",
       " 'work',\n",
       " 'invert',\n",
       " 'longer',\n",
       " 'ice',\n",
       " '810',\n",
       " 'make',\n",
       " 'red',\n",
       " 'shallots',\n",
       " 'bouillon',\n",
       " 'melts',\n",
       " 'tablespoon',\n",
       " 'working',\n",
       " 'vegetable',\n",
       " 'drippings',\n",
       " 'piece',\n",
       " 'salad',\n",
       " 'rolling',\n",
       " '2030',\n",
       " 'oiled',\n",
       " 'need',\n",
       " 'bits',\n",
       " 'frozen',\n",
       " 'soup',\n",
       " 'shell',\n",
       " '1520',\n",
       " 'tomatoes',\n",
       " 'toothpick',\n",
       " 'tortilla',\n",
       " 'seam',\n",
       " 'sugar',\n",
       " 'excess',\n",
       " 'pieces',\n",
       " 'start',\n",
       " 'firmly',\n",
       " 'across',\n",
       " 'boil',\n",
       " 'saut',\n",
       " 'use',\n",
       " 'till',\n",
       " 'spices',\n",
       " 'want',\n",
       " 'peaks',\n",
       " 'cutter',\n",
       " 'pancake',\n",
       " 'pork',\n",
       " 'serving',\n",
       " 'frosting',\n",
       " 'beating',\n",
       " 'reheat',\n",
       " 'stirring',\n",
       " 'mushrooms',\n",
       " 'applesauce',\n",
       " 'wet',\n",
       " 'refrigerator',\n",
       " 'lime',\n",
       " 'crust',\n",
       " 'put',\n",
       " 'bun',\n",
       " 'mint',\n",
       " 'edge',\n",
       " 'large',\n",
       " 'whole',\n",
       " 'coconut',\n",
       " 'made',\n",
       " 'sprouts',\n",
       " 'sweet',\n",
       " 'spice',\n",
       " 'jam',\n",
       " 'drop',\n",
       " 'flip',\n",
       " 'makes',\n",
       " 'couscous',\n",
       " 'pulp',\n",
       " 'inches',\n",
       " 'extract',\n",
       " 'blend',\n",
       " 'cookie',\n",
       " 'sandwich',\n",
       " '60',\n",
       " 'biscuit',\n",
       " 'flavors',\n",
       " 'open',\n",
       " 'split',\n",
       " 'rub',\n",
       " 'w',\n",
       " 'taco',\n",
       " 'cheeses',\n",
       " 'cut',\n",
       " 'square',\n",
       " 'whisk',\n",
       " 'around',\n",
       " 'amount',\n",
       " 'tightly',\n",
       " 'spring',\n",
       " 'colander',\n",
       " 'powder',\n",
       " 'ovenproof',\n",
       " 'breasts',\n",
       " 'coffee',\n",
       " 'jalapeno',\n",
       " 'yolk',\n",
       " 'golden',\n",
       " 'wheat',\n",
       " 'among',\n",
       " 'cups',\n",
       " 'zest',\n",
       " '9x13',\n",
       " 'everything',\n",
       " 'strain',\n",
       " 'later',\n",
       " 'flat',\n",
       " 'pour',\n",
       " 'bundt',\n",
       " 'additional',\n",
       " 'pressing',\n",
       " 'ready',\n",
       " 'per',\n",
       " 'sour',\n",
       " 'cornmeal',\n",
       " 'sprinkle',\n",
       " 'another',\n",
       " 'al',\n",
       " 'med',\n",
       " 'whipping',\n",
       " 'whipped',\n",
       " 'forms',\n",
       " 'crumbled',\n",
       " 'prefer',\n",
       " 'cayenne',\n",
       " 'paprika',\n",
       " 'add',\n",
       " 'egg',\n",
       " 'light',\n",
       " 'prevent',\n",
       " 'moderate',\n",
       " 'tomato',\n",
       " 'fluffy',\n",
       " 'pot',\n",
       " 'shortening',\n",
       " 'fruit',\n",
       " 'mushroom',\n",
       " 'eggplant',\n",
       " 'mediumhigh',\n",
       " 'wrap',\n",
       " 'peaches',\n",
       " 'zucchini',\n",
       " 'crumble',\n",
       " '23',\n",
       " 'point',\n",
       " 'adjust',\n",
       " 'whisking',\n",
       " '2025',\n",
       " 'burgers',\n",
       " 'drain',\n",
       " 'airtight',\n",
       " 'board',\n",
       " 'bowl',\n",
       " 'rice',\n",
       " 'see',\n",
       " 'onion',\n",
       " 'greased',\n",
       " 'electric',\n",
       " 'nuts',\n",
       " 'substitute',\n",
       " 'bay',\n",
       " 'fine',\n",
       " 'depending',\n",
       " 'beef',\n",
       " 'fork',\n",
       " 'wine',\n",
       " 'feta',\n",
       " 'coating',\n",
       " 'touch',\n",
       " 'optional',\n",
       " 'slicing',\n",
       " 'gently',\n",
       " 'celery',\n",
       " 'begins',\n",
       " 'done',\n",
       " 'jar',\n",
       " 'batches',\n",
       " 'translucent',\n",
       " 'liquid',\n",
       " 'part',\n",
       " 'quarter',\n",
       " 'sieve',\n",
       " 'measure',\n",
       " 'inside',\n",
       " '9',\n",
       " 'soak',\n",
       " 'soy',\n",
       " 'pat',\n",
       " 'basil',\n",
       " 'bit',\n",
       " 'grind',\n",
       " 'avocado',\n",
       " 'lift',\n",
       " 'seed',\n",
       " 'stirfry',\n",
       " 'slightly',\n",
       " 'thicken',\n",
       " 'stuffing',\n",
       " 'f',\n",
       " '8',\n",
       " 'stir',\n",
       " 'ground',\n",
       " 'tossing',\n",
       " 'less',\n",
       " 'repeat',\n",
       " 'filling',\n",
       " 'scatter',\n",
       " 'roasted',\n",
       " 'smaller',\n",
       " 'pesto',\n",
       " 'butter',\n",
       " 'lightly',\n",
       " 'parchment',\n",
       " 'day',\n",
       " 'punch',\n",
       " 'confectioners',\n",
       " 'double',\n",
       " 'cinnamon',\n",
       " 'eat',\n",
       " '325f',\n",
       " 'thick',\n",
       " 'becomes',\n",
       " 'greens',\n",
       " 'caramel',\n",
       " 'leaving',\n",
       " 'coarse',\n",
       " 'cocoa',\n",
       " 'boiler',\n",
       " '24',\n",
       " 'fresh',\n",
       " 'baste',\n",
       " 'rosemary',\n",
       " 'bowls',\n",
       " 'pound',\n",
       " 'cooled',\n",
       " 'pasta',\n",
       " 'still',\n",
       " 'preheat',\n",
       " 'toast',\n",
       " 'hand',\n",
       " 'oats',\n",
       " '400f',\n",
       " 'lamb',\n",
       " 'graham',\n",
       " 'dough',\n",
       " 'grated',\n",
       " 'heavy',\n",
       " 'garlic',\n",
       " 'muffins',\n",
       " 'turmeric',\n",
       " 'wire',\n",
       " 'corn',\n",
       " 'wok',\n",
       " 'onto',\n",
       " 'pita',\n",
       " 'extra',\n",
       " 'mins',\n",
       " 'ingredients',\n",
       " 'machine',\n",
       " 'nicely',\n",
       " 'crackers',\n",
       " 'doesnt',\n",
       " '450',\n",
       " '3',\n",
       " 'shallow',\n",
       " 'absorbed',\n",
       " 'roast',\n",
       " 'cucumber',\n",
       " 'metal',\n",
       " 'sheets',\n",
       " 'peel',\n",
       " 'instructions',\n",
       " '400',\n",
       " 'springform',\n",
       " 'peppers',\n",
       " 'set',\n",
       " 'step',\n",
       " 'ends',\n",
       " 'without',\n",
       " 'medium',\n",
       " 'fill',\n",
       " '68',\n",
       " 'noodles',\n",
       " 'doubled',\n",
       " 'baking',\n",
       " 'low',\n",
       " 'heat',\n",
       " '40',\n",
       " 'several',\n",
       " 'chocolate',\n",
       " 'bring',\n",
       " 'dissolved',\n",
       " 'loosely',\n",
       " 'dust',\n",
       " 'knead',\n",
       " 'spatula',\n",
       " 'dente',\n",
       " 'leave',\n",
       " 'scallions',\n",
       " 'frost',\n",
       " 'min',\n",
       " 'slices',\n",
       " 'serve',\n",
       " 'yellow',\n",
       " 'order',\n",
       " 'deep',\n",
       " 'dressing',\n",
       " 'white',\n",
       " 'mayonnaise',\n",
       " 'frequently',\n",
       " '50',\n",
       " 'crumb',\n",
       " 'sticky',\n",
       " 'barbecue',\n",
       " 'pulse',\n",
       " 'quarters',\n",
       " 'minutes',\n",
       " 'really',\n",
       " '300',\n",
       " 'tsp',\n",
       " 'doneness',\n",
       " 'breadcrumbs',\n",
       " 'cereal',\n",
       " 'cheddar',\n",
       " 'warm',\n",
       " 'saute',\n",
       " 'carefully',\n",
       " 'run',\n",
       " 'portions',\n",
       " 'buttermilk',\n",
       " 'mashed',\n",
       " 'chill',\n",
       " 'finish',\n",
       " 'floured',\n",
       " 'pie',\n",
       " 'coat',\n",
       " 'casserole',\n",
       " 'salt',\n",
       " 'surface',\n",
       " 'black',\n",
       " 'meatballs',\n",
       " 'tins',\n",
       " 'carrot',\n",
       " 'turning',\n",
       " 'cabbage',\n",
       " 'enjoy',\n",
       " 'oven',\n",
       " 'paste',\n",
       " 'seeds',\n",
       " 'first',\n",
       " 'clean',\n",
       " 'fry',\n",
       " 'coriander',\n",
       " 'sized',\n",
       " 'warmed',\n",
       " 'lentils',\n",
       " '7',\n",
       " 'wooden',\n",
       " 'favorite',\n",
       " 'recipe',\n",
       " 'mozzarella',\n",
       " '375',\n",
       " '13x9',\n",
       " 'let',\n",
       " 'icing',\n",
       " 'hands',\n",
       " 'full',\n",
       " 'approximately',\n",
       " 'mix',\n",
       " 'crumbs',\n",
       " 'soft',\n",
       " 'dried',\n",
       " 'cube',\n",
       " 'cheesecake',\n",
       " '425',\n",
       " 'air',\n",
       " 'kitchen',\n",
       " 'directed',\n",
       " 'starting',\n",
       " '10',\n",
       " 'wide',\n",
       " 'alternately',\n",
       " 'comes',\n",
       " 'four',\n",
       " 'skewer',\n",
       " 'immediately',\n",
       " 'pick',\n",
       " 'press',\n",
       " 'thoroughly',\n",
       " 'granulated',\n",
       " 'mixed',\n",
       " 'smooth',\n",
       " 'parsley',\n",
       " 'mustard',\n",
       " 'added',\n",
       " 'scallops',\n",
       " 'better',\n",
       " 'basting',\n",
       " 'chilies',\n",
       " 'quart',\n",
       " 'slow',\n",
       " 'berries',\n",
       " 'remove',\n",
       " '15',\n",
       " 'tbs',\n",
       " 'dutch',\n",
       " 'season',\n",
       " 'yogurt',\n",
       " 'cover',\n",
       " 'asparagus',\n",
       " 'banana',\n",
       " 'sure',\n",
       " 'possible',\n",
       " 'couple',\n",
       " 'increase',\n",
       " 'outside',\n",
       " 'degree',\n",
       " 'racks',\n",
       " 'reserve',\n",
       " 'processor',\n",
       " 'evaporated',\n",
       " 'bacon',\n",
       " 'side',\n",
       " 'stew',\n",
       " 'generously',\n",
       " 'layer',\n",
       " 'position',\n",
       " 'lettuce',\n",
       " 'broth',\n",
       " 'dip',\n",
       " 'steaks',\n",
       " 'bubbly',\n",
       " 'whites',\n",
       " 'evenly',\n",
       " 'cooking',\n",
       " 'breast',\n",
       " 'seal',\n",
       " 'batter',\n",
       " '325',\n",
       " 'skins',\n",
       " '2530',\n",
       " 'oregano',\n",
       " 'single',\n",
       " 'pull',\n",
       " 'salmon',\n",
       " 'go',\n",
       " 'fahrenheit',\n",
       " 'sharp',\n",
       " 'come',\n",
       " 'crisp',\n",
       " 'reduce',\n",
       " 'loosen',\n",
       " 'sliced',\n",
       " 'juices',\n",
       " 'dishes',\n",
       " 'pecans',\n",
       " 'mayo',\n",
       " 'heated',\n",
       " 'plastic',\n",
       " 'third',\n",
       " 'reduced',\n",
       " 'cooling',\n",
       " 'soda',\n",
       " 'equal',\n",
       " 'color',\n",
       " 'potatoes',\n",
       " 'sugars',\n",
       " 'softened',\n",
       " 'juice',\n",
       " 'stiff',\n",
       " 'choice',\n",
       " 'hours',\n",
       " '1012',\n",
       " 'transfer',\n",
       " 'wilted',\n",
       " 'according',\n",
       " 'rise',\n",
       " 'apart',\n",
       " 'entire',\n",
       " 'biscuits',\n",
       " 'buns',\n",
       " 'spreading',\n",
       " 'sides',\n",
       " 'chili',\n",
       " 'dissolve',\n",
       " 'left',\n",
       " 'discard',\n",
       " 'mixture',\n",
       " '2quart',\n",
       " '13',\n",
       " 'cornstarch',\n",
       " 'cookies',\n",
       " 'dill',\n",
       " '1',\n",
       " 'three',\n",
       " 'starts',\n",
       " 'sauce',\n",
       " 'removing',\n",
       " 'lumps',\n",
       " 'parmesan',\n",
       " 'pudding',\n",
       " 'dice',\n",
       " 'finished',\n",
       " 'bake',\n",
       " 'rolls',\n",
       " 'italian',\n",
       " 'line',\n",
       " 'dredge',\n",
       " 'oil',\n",
       " 'crispy',\n",
       " 'hold',\n",
       " 'five',\n",
       " 'stock',\n",
       " 'crockpot',\n",
       " 'time',\n",
       " 'hot',\n",
       " '9inch',\n",
       " 'melt',\n",
       " 'fingers',\n",
       " 'sit',\n",
       " 'tofu',\n",
       " 'centre',\n",
       " 'good',\n",
       " 'clear',\n",
       " 'room',\n",
       " 'temperature',\n",
       " 'cloves',\n",
       " 'inch',\n",
       " 'close',\n",
       " 'cilantro',\n",
       " 'enough',\n",
       " 'strips',\n",
       " 'sandwiches',\n",
       " 'olives',\n",
       " 'long',\n",
       " 'thickens',\n",
       " 'glasses',\n",
       " 'chiles',\n",
       " 'baked',\n",
       " 'bag',\n",
       " 'almonds',\n",
       " '20',\n",
       " '2',\n",
       " 'careful',\n",
       " 'store',\n",
       " 'yeast',\n",
       " 'directions',\n",
       " 'rinse',\n",
       " 'uncover',\n",
       " 'rounds',\n",
       " 'hard',\n",
       " 'curry',\n",
       " 'cherry',\n",
       " 'topping',\n",
       " 'top',\n",
       " 'ungreased',\n",
       " 'halves',\n",
       " 'pineapple',\n",
       " 'towel',\n",
       " 'cakes',\n",
       " 'aside',\n",
       " 'fillets',\n",
       " 'one',\n",
       " 'moist',\n",
       " 'scrape',\n",
       " 'beginning',\n",
       " '350',\n",
       " 'shrimp',\n",
       " '510',\n",
       " 'dipping',\n",
       " '4inch',\n",
       " '1015',\n",
       " 'handle',\n",
       " 'boiling',\n",
       " 'powdered',\n",
       " 'simmering',\n",
       " 'garnish',\n",
       " 'two',\n",
       " 'nutmeg',\n",
       " 'salsa',\n",
       " 'minute',\n",
       " 'take',\n",
       " 'lay',\n",
       " 'wax',\n",
       " 'rind',\n",
       " 'size',\n",
       " 'loaves',\n",
       " 'meanwhile',\n",
       " 'bbq',\n",
       " 'tablespoons',\n",
       " 'skin',\n",
       " '16',\n",
       " 'peanuts',\n",
       " 'bell',\n",
       " 'reaches',\n",
       " 'ricotta',\n",
       " 'fully',\n",
       " 'gravy',\n",
       " '4',\n",
       " 'steak',\n",
       " 'cutting',\n",
       " 'filled',\n",
       " 'blueberries',\n",
       " 'tortillas',\n",
       " 'every',\n",
       " 'dont',\n",
       " 'chopped',\n",
       " 'cauliflower',\n",
       " 'diced',\n",
       " 'last',\n",
       " 'potato',\n",
       " 'bite',\n",
       " 'simmer',\n",
       " 'leaves',\n",
       " 'lemon',\n",
       " 'vegetables',\n",
       " 'turkey',\n",
       " 'iron',\n",
       " 'round',\n",
       " 'veggies',\n",
       " 'crushed',\n",
       " 'sesame',\n",
       " 'plates',\n",
       " 'break',\n",
       " '1inch',\n",
       " 'spoon',\n",
       " 'browned',\n",
       " 'circle',\n",
       " 'sausage',\n",
       " 'like',\n",
       " 'tuna',\n",
       " '5',\n",
       " 'either',\n",
       " 'consistency',\n",
       " 'thickened',\n",
       " 'high'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words = word_freq.most_common(1000)\n",
    "most_common_words = {word for word, _ in most_common_words}\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'add' in most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "new_steps = []  # 创建一个新的列表来存放更新后的步骤\n",
    "for steps_str in data['steps']:\n",
    "    steps_list = eval(steps_str)\n",
    "    steps_list = ''.join(steps_list)\n",
    "    # 使用列表推导式过滤单词\n",
    "    words_filtered = []\n",
    "\n",
    "    for word in steps_list.split(\" \"):\n",
    "\n",
    "        if word in most_common_words:\n",
    "\n",
    "            words_filtered.append(word)\n",
    "\n",
    "    # 将过滤后的steps添加到新的列表中\n",
    "    new_steps.append(' '.join(words_filtered))\n",
    "\n",
    "# 将原来的data['steps']更新为新的步骤列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text and building vocabulary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building vocabulary:   0%|                           | 0/138981 [00:00<?, ?it/s]/usr/lib/python3/dist-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "Building vocabulary: 100%|████████████| 138981/138981 [00:17<00:00, 7869.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BoW...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing BoW: 100%|██████████████████| 138981/138981 [00:17<00:00, 7851.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW representation computed.\n",
      "Computing TF-IDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing TF-IDF: 100%|███████████████| 138981/138981 [00:17<00:00, 7868.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix computed.\n"
     ]
    }
   ],
   "source": [
    "steps_text = new_steps\n",
    "\n",
    "print(\"Preprocessing text and building vocabulary...\")\n",
    "vectorizer = build_vocabulary(steps_text)\n",
    "\n",
    "print(\"Computing BoW...\")\n",
    "bow_matrix = compute_bow(steps_text, vectorizer)\n",
    "print(\"BoW representation computed.\")\n",
    "\n",
    "print(\"Computing TF-IDF...\")\n",
    "tfidf_matrix = compute_tfidf(steps_text, vectorizer.vocabulary_)\n",
    "print(\"TF-IDF matrix computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138981, 942)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138981, 942)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding texts: 100%|█████████████████| 138981/138981 [01:07<00:00, 2056.90it/s]\n",
      "Extracting features: 100%|██████████████████| 8687/8687 [24:42<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138981, 768)\n"
     ]
    }
   ],
   "source": [
    "steps_text = new_steps\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# 1. 加载预训练的 BERT Tokenizer 和 BERT 模型\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# 2. 准备数据处理的函数\n",
    "def encode_texts(texts, tokenizer, max_length=512):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in tqdm(texts, desc=\"Encoding texts\"):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True, # 添加 '[CLS]' 和 '[SEP]'\n",
    "            max_length=max_length,   # 设定最大文本长度\n",
    "            padding='max_length',    # 添加 padding\n",
    "            return_attention_mask=True, # 返回 attention mask\n",
    "            return_tensors='pt',     # 返回 PyTorch tensors\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        # 添加编码后的文本到列表\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    # 转换为 tensor\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# 3. 文本编码\n",
    "input_ids, attention_masks = encode_texts(steps_text, tokenizer)\n",
    "\n",
    "# 4. 创建 DataLoader\n",
    "batch_size = 16\n",
    "dataset = TensorDataset(input_ids, attention_masks)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "bert_embeddings = []\n",
    "\n",
    "# 遍历 DataLoader\n",
    "for batch in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, attention_masks = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 前向传播，获取编码层的输出\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "    \n",
    "    # 获取最后一层的隐藏状态\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    \n",
    "    # 对所有 token 的输出进行平均，作为句子表示\n",
    "    sentence_embedding = torch.mean(last_hidden_state, dim=1)\n",
    "    bert_embeddings.append(sentence_embedding)\n",
    "\n",
    "bert_embeddings = torch.cat(bert_embeddings, dim=0)\n",
    "bert_embeddings = bert_embeddings.to('cpu').numpy()\n",
    "print(bert_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bert_embeddings, 'bert_embeddings.pt')\n",
    "torch.save(model.state_dict(), 'bert_model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "bert_embeddings = torch.load('bert_embeddings.pt')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.load_state_dict(torch.load('bert_model_weights.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138981, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138981 entries, 0 to 138980\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   name               138981 non-null  object \n",
      " 1   id                 138981 non-null  int64  \n",
      " 2   minutes            138981 non-null  int64  \n",
      " 3   contributor_id     138981 non-null  int64  \n",
      " 4   submitted          138981 non-null  object \n",
      " 5   tags               138981 non-null  object \n",
      " 6   n_steps            138981 non-null  int64  \n",
      " 7   steps              138981 non-null  object \n",
      " 8   description        136025 non-null  object \n",
      " 9   ingredients        138981 non-null  object \n",
      " 10  n_ingredients      138981 non-null  int64  \n",
      " 11  calories           138981 non-null  float64\n",
      " 12  total_fat          138981 non-null  float64\n",
      " 13  sugar              138981 non-null  float64\n",
      " 14  sodium             138981 non-null  float64\n",
      " 15  protein            138981 non-null  float64\n",
      " 16  saturated_fat      138981 non-null  float64\n",
      " 17  carbohydrates      138981 non-null  float64\n",
      " 18  calories_log       138981 non-null  float64\n",
      " 19  total_fat_log      138981 non-null  float64\n",
      " 20  sugar_log          138981 non-null  float64\n",
      " 21  sodium_log         138981 non-null  float64\n",
      " 22  protein_log        138981 non-null  float64\n",
      " 23  saturated_fat_log  138981 non-null  float64\n",
      " 24  carbohydrates_log  138981 non-null  float64\n",
      "dtypes: float64(14), int64(5), object(6)\n",
      "memory usage: 26.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_file = '../../dataset/processed/train_data.csv'\n",
    "train_data = pd.read_csv(train_file)\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们现在有一个通过bert提取的对于数据集中step的feature\n",
    "# 现在希望把这个数据通过PCA降低到十个dim\n",
    "# 然后作为新的col写回到数据集中\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "train_file = '../../dataset/processed/train_data.csv'\n",
    "train_data = pd.read_csv(train_file)\n",
    "\n",
    "# 定义PCA变换器，指定我们想要的组件数量为10\n",
    "pca = PCA(n_components=768)\n",
    "\n",
    "# 对BERT特征应用PCA变换\n",
    "bert_embeddings_reduced = pca.fit_transform(bow_matrix)\n",
    "\n",
    "print(\"PCA features added to the data and saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '../../dataset/processed/train_data.csv'\n",
    "test_data = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error (MSE) on test set: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 导入数据和BERT特征\n",
    "valid_data = pd.read_csv(test_file)\n",
    "\n",
    "# 定义BERT特征的维度和数据点的数量\n",
    "n_samples = valid_data.shape[0]\n",
    "n_features = 765\n",
    "\n",
    "# 生成随机特征\n",
    "random_features = np.random.rand(n_samples, n_features)\n",
    "\n",
    "X_random = pd.DataFrame(random_features, columns=[f'random_feature_{i+1}' for i in range(n_features)])\n",
    "\n",
    "\n",
    "# 准备训练数据（BERT特征列）\n",
    "\n",
    "X_other_features = valid_data[['total_fat', 'sugar', 'sodium', 'protein', 'saturated_fat']]\n",
    "\n",
    "# 合并随机特征和其他特征列\n",
    "# X = pd.DataFrame(bow_matrix.toarray())\n",
    "\n",
    "X = pd.concat([pd.DataFrame(tfidf_matrix.toarray())], axis=1)\n",
    "\n",
    "\n",
    "# 准备目标值（calories列）\n",
    "y = valid_data['calories_log']\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化线性回归模型\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# 拟合线性回归模型\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# 使用模型对测试集进行预测\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# 计算预测的均方误差（MSE）\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"The mean squared error (MSE) on test set: {mse:.2f}\")\n",
    "\n",
    "# 如果需要，可以保存模型，以便以后使用\n",
    "# from joblib import dump\n",
    "# dump(regressor, 'calories_regressor.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error (MSE) on test set: 0.52 -> 0.50 5% -> 0.48\n",
    "# Random 0.55\n",
    "# tf-idf 0.74\n",
    "# bow 0.76\n",
    "# bert 0.75\n",
    "\n",
    "# bert + tfidf = 0.73\n",
    "# bert + bow = 0.74\n",
    "# bow + tfidf = 0.74\n",
    "# bert + tfidf + bow = 0.73\n",
    "\n",
    "# tfidf = 0.74\n",
    "# bert = 0.75\n",
    "# bow = 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "test_file = '../../dataset/processed/train_proced.csv'\n",
    "test_data = pd.read_csv(test_file)\n",
    "valid_data = pd.read_csv(test_file)\n",
    "\n",
    "X_other_features = valid_data[['total_fat', 'sugar', 'sodium', 'protein', 'saturated_fat']]\n",
    "\n",
    "\n",
    "# 假设您已经有了目标变量 y （例如，您的回归目标）\n",
    "y = valid_data['calories_log']\n",
    "\n",
    "\n",
    "# 定义BERT特征的维度和数据点的数量\n",
    "n_samples = valid_data.shape[0]\n",
    "n_features = 10\n",
    "\n",
    "# 生成随机特征\n",
    "random_features = np.random.rand(n_samples, n_features)\n",
    "\n",
    "X_random = pd.DataFrame(random_features, columns=[f'random_feature_{i+1}' for i in range(n_features)])\n",
    "\n",
    "\n",
    "# 分割数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化Lasso回归模型\n",
    "# alpha是正则化强度，可以通过交叉验证来选择最佳值\n",
    "lasso_regressor = Lasso(alpha=0.000000001)\n",
    "\n",
    "# 拟合模型\n",
    "lasso_regressor.fit(X_train, y_train)\n",
    "\n",
    "# 可以使用X_test来进行模型评估\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = lasso_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random 0.92\n",
    "\n",
    "Bert Mean Squared Error: 0.9226066329299135\n",
    "Ran Mean Squared Error: 0.9226066232306231"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
